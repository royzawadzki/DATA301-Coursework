{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and English model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f310b5b2de48a5d4548b4e8ef02ae0ee",
     "grade": false,
     "grade_id": "cell-1e74b51c230de873",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook we are using the default English corpus of spaCy that includes a relatively small model (see https://spacy.io/models/en for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1fd06d786fc5f1d02dddcb4027621e95",
     "grade": false,
     "grade_id": "cell-555e70d096404765",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a set of words related to animals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9687baed006a037abaf4482964652e59",
     "grade": false,
     "grade_id": "cell-5f6381a35afc8f1d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "animals = 'horse cat kitten puppy dog mouse pony'\n",
    "tokens = nlp(animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tokens` is an iterator of tokens, let's grab the horse token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0bc9a4fa676f322d3af92d0aae44de89",
     "grade": false,
     "grade_id": "cell-41c3a211089afd55",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "horse = tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the actual word the token points to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e618fa85f95550bf726b48cf4eaadefa",
     "grade": false,
     "grade_id": "cell-49f9f6da4aa30822",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horse'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(horse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea of word vectors is that for each word, there is a corresponding 1d vector (a NumPy array). These word vectors encode information about the meaning of the word and its function in sentences. Here are the first 10 elements of the word vector for *horse*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "37b3a8ac2cc0a1080d8eb4f686cdf67b",
     "grade": false,
     "grade_id": "cell-a3a77a1e427171a5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.19629192,  3.07423615, -1.23166108,  0.56064409, -0.5370236 ,\n",
       "        2.51031804, -3.66074538,  1.92708302,  1.98932076,  2.73977804], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horse.vector[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Python `dict` named `wordvecs` where the keys are the string names of the animals and the values are the `np.ndarray` word vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b32f88c608975a13fe71c4fd988fb27c",
     "grade": false,
     "grade_id": "cell-fcae03126dfb42e4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "animals = 'horse cat kitten puppy dog mouse pony'\n",
    "tokens = nlp(animals)\n",
    "wordvecs = {}\n",
    "for token in tokens:\n",
    "    wordvecs[str(token)] = token.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0041bac8a7a5f6f35e8830e552495e76",
     "grade": true,
     "grade_id": "cell-db9b386afdf07fae",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(wordvecs)==7\n",
    "assert set(animals.split(' '))==set(wordvecs.keys())\n",
    "assert all(isinstance(v, np.ndarray) for v in wordvecs.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `vector_norm` that computes the $L_2$ vector norm:\n",
    "\n",
    "$$\n",
    "\\left|\\vec{v}\\right| = \\sqrt{ \\sum_{i=0}^{n-1} v_i^2 }\n",
    "$$\n",
    "\n",
    "of a NumPy array. Don't use any `for` loops and don't use anything from `np.linalg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  4,  9, 16, 25])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_test = np.array([1,2,3,4,5])\n",
    "array_test ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9ea6ae1a343ca8bda59a3959716a80b7",
     "grade": false,
     "grade_id": "cell-69e3ba6ed6068ee6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def vector_norm(v):\n",
    "    \"\"\"Compute the L2 norm of a 1d NumPy array v.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    l2 = np.sum(v ** 2) ** .5\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `vector_norm` function should pass these tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "210f41d545fc0f90713108edac6378bb",
     "grade": true,
     "grade_id": "cell-885f91d7bd2d8a63",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "a = np.linspace(0,10.0,10)\n",
    "assert np.allclose(vector_norm(a), np.linalg.norm(a))\n",
    "assert np.allclose(vector_norm(np.array([1,0])), 1.0)\n",
    "assert np.allclose(vector_norm(np.array([1,1])), np.sqrt(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `inner_product` that computes the dot or inner product:\n",
    "\n",
    "$$\n",
    "\\vec{v} \\cdot \\vec{w} = \\sum_{i=0}^{n-1} v_i w_i\n",
    "$$\n",
    "\n",
    "of two NumPy arrays. Don't use any `for` loops and don't use `np.dot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0d5c5793aaceb6bad49030aa62dd8b2f",
     "grade": false,
     "grade_id": "cell-e0171b5cc42cfa97",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def inner_product(v, w):\n",
    "    \"\"\"Compute the inner/dot product of two 1d NumPy arrays v, w.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    inner = np.multiply(v,w)\n",
    "    v_dot_w = np.sum(inner)\n",
    "    return v_dot_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `inner_product` function should pass these tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a3b73b454ddfbcf15f5cb0b06bcb4fee",
     "grade": true,
     "grade_id": "cell-f361cfbb5f60269c",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(inner_product(np.array([0,1]),np.array([1,0])), 0.0)\n",
    "assert np.allclose(inner_product(np.array([1,0]),np.array([1,0])), 1.0)\n",
    "assert np.allclose(inner_product(np.array([1,2]),np.array([3,4])), 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have represented different entities, such as words, as vectors, it is often useful to have a measure of how similar two vectors are to each other. For example, from a language and meaning perspective, we would expect *dog* and *puppy* to be more similar than *shark* and *kitten*. One common way of measuring this type of similarity is the [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity), which is defined as follows:\n",
    "\n",
    "$$\n",
    "S(\\vec{v}, \\vec{w}) = \\frac{\\vec{v}\\cdot\\vec{w}}{\\left|\\vec{v}\\right|\\left|\\vec{w}\\right|}\n",
    "$$\n",
    "\n",
    "Write a function `similarity`, that computes the cosine similarity of two vectors that are 1d NumPy arrays. Use the above `inner_product` and `vector_norm` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "eb01da461e5a11a0a0436639ec1a1d8d",
     "grade": false,
     "grade_id": "cell-66f9101819d1808f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def similarity(v, w):\n",
    "    \"\"\"Compute the cosine similarity of two 1d NumPy arrays v, w.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    similiarity = inner_product(v,w) / (vector_norm(v) * vector_norm(w))\n",
    "    return similiarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the similarity between different pairs of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0176e75ddd5bbdd66e287700b6ba9c14",
     "grade": false,
     "grade_id": "cell-742951646b252b93",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36603757321214497"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(wordvecs['horse'], wordvecs['pony'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b65e3f53c0ab56c0979c191ff3ced3d5",
     "grade": false,
     "grade_id": "cell-d4878926946b1830",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37314380206073866"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(wordvecs['kitten'], wordvecs['puppy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are a bit confusing: you might think that *horse* and *pony* would be more similar than *kitten* and *puppy*. This particular corpus of word vectors is rather small and as a result is not particularly accurate. More accurate sets of word vectors are available with spaCy, but they take more memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that words should have a self-similarity of `1.0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "39a241a64ebcb0f7bbd452011d60b8a0",
     "grade": false,
     "grade_id": "cell-9ebfe9137665894b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(wordvecs['cat'], wordvecs['cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `similarity` function should pass the following tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "acd2cf9ed58d2022239b6582f68e11d2",
     "grade": true,
     "grade_id": "cell-9f94f1b7f9f47fd6",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "for k, v in wordvecs.items():\n",
    "    assert np.allclose(similarity(v,v), 1.0)\n",
    "assert np.allclose(similarity(wordvecs['horse'], wordvecs['pony']),0.36603758)\n",
    "assert np.allclose(similarity(wordvecs['kitten'], wordvecs['puppy']),0.37314379)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding similar words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `most_similar` that takes a single word (like `puppy`) and the `dict` of word vectors (whose keys are word and values are corresponding word vectors) and returns the word in the word vector set that is most cosine-similar to `word` (other than the word itself). Return a tuple of the matched word and its cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f710f18faaaa99aa95873fc2d7537449",
     "grade": false,
     "grade_id": "cell-5f98b654c61b9d0e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def most_similar(word, wordvecs):\n",
    "    \"\"\"Find the most similar word in wordvecs to the input word.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    word : str\n",
    "        A single input word.\n",
    "    wordvecs : dict\n",
    "        A dict whose keys are words and values are word vectors.\n",
    "    \n",
    "    Return\n",
    "    ======\n",
    "    (word, similarity)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    biggest_value = 0\n",
    "    biggest_key = \"\"\n",
    "    for key in wordvecs:\n",
    "        if key == word:\n",
    "            continue\n",
    "        else:\n",
    "            cos_sim = similarity(wordvecs[word], wordvecs[key])\n",
    "            if cos_sim > biggest_value:\n",
    "                biggest_value = cos_sim\n",
    "                biggest_word = key\n",
    "    return (biggest_word, biggest_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that *mouse* is the most similar word to *horse* (which is silly, but expected given this small dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b04a500a08b7c19ee165f3d7dd534639",
     "grade": false,
     "grade_id": "cell-50b3e53e745d1a76",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mouse', 0.51169699114944167)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('horse', wordvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a list of the most similar words to all the words in the word vector set. Save your list in a variable named `matches`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ac68e3de5dfce033c59213b1b7285526",
     "grade": false,
     "grade_id": "cell-e602bd091ab9cd17",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "matches = []\n",
    "for key in wordvecs:\n",
    "    matches.append(most_similar(key, wordvecs)[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `most_similar` function should pass the following test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "278574fe6c8f8b59f163fdd180b1a721",
     "grade": true,
     "grade_id": "cell-9cccb66435d2b047",
     "locked": true,
     "points": 8,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "match = most_similar('horse', wordvecs)\n",
    "assert match[0]=='mouse'\n",
    "assert np.allclose(match[1], 0.51169699)\n",
    "assert matches==['mouse', 'mouse', 'mouse', 'dog', 'mouse', 'dog', 'mouse']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
